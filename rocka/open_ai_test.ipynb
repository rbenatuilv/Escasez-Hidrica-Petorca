{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import requests\n",
    "from requests import Response\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2base64(image: Image) -> str:\n",
    "    tmp = io.BytesIO()\n",
    "    image.save(tmp, format=\"WEBP\")\n",
    "    return base64.b64encode(tmp.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_chatgpt(image: Image) -> Response:\n",
    "    image = image.resize((64, 64))\n",
    "    image_base64 = img2base64(image)\n",
    "\n",
    "     \n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"Your task is to classify the image into one of four categories: urban, crop, mountain, or forest. Your output should be in JSON format as follows: {'category': 'the category of the image'}.\",\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What category does this image belong to?\"\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
    "            }\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "  \"max_tokens\": 100\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro-vision')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_imagen(imagen: Image):\n",
    "\n",
    "    ancho, alto = imagen.size\n",
    "\n",
    "    if not (ancho % 128 == 0 and alto % 128 == 0):\n",
    "        raise ValueError()\n",
    "\n",
    "    tamaño_trozo = 128\n",
    "    pos_y = 0\n",
    "    pos_x = 0\n",
    "    for y in range(0, alto, tamaño_trozo):\n",
    "        for x in range(0, ancho, tamaño_trozo):\n",
    "            trozo = imagen.crop((x, y, x + tamaño_trozo, y + tamaño_trozo))\n",
    "            trozo.save(f\"./chunks/{pos_x}-{pos_y}.jpg\")\n",
    "            pos_x = pos_x + 1\n",
    "        pos_y = pos_y + 1\n",
    "        pos_x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clasificar_gemini(image: Image, model=model):\n",
    "    image = image.resize((64, 64))\n",
    "\n",
    "    imagen_bytes = io.BytesIO()\n",
    "    image.save(imagen_bytes, format='JPEG')\n",
    "    bytes_de_imagen = imagen_bytes.getvalue()\n",
    "\n",
    "    response = model.generate_content(\n",
    "        glm.Content(\n",
    "            parts = [\n",
    "                glm.Part(text=\"Your task is to classify the image into one of four categories: URBAN, CROP, DRY LAND, FOREST. Your output should be in JSON format as follows: {'category': 'the category of the image'}.\"),\n",
    "                glm.Part(\n",
    "                    inline_data=glm.Blob(\n",
    "                        mime_type='image/jpeg',\n",
    "                        data=bytes_de_imagen\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "        stream=True)\n",
    "    \n",
    "    response.resolve()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = Image.open(\"./chunk_rgb_640x640.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "dividir_imagen(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "archivos = os.listdir(\"./chunks\")\n",
    "print(len(archivos))\n",
    "# URBAN, CROP, DRY LAND, FOREST\n",
    "for i, path in enumerate(archivos):\n",
    "    image = Image.open(f\"./chunks/{path}\")\n",
    "    res = clasificar_gemini(image)\n",
    "    text = res.text\n",
    "\n",
    "    if \"URBAN\" in text:\n",
    "        imagen = Image.new(\"RGB\", (128, 128), (0,0,255))\n",
    "        imagen.save(f\"./chunks_process/{path}\")\n",
    "    elif \"CROP\" in text:\n",
    "        imagen = Image.new(\"RGB\", (128, 128), (255,255,0))\n",
    "        imagen.save(f\"./chunks_process/{path}\")\n",
    "    elif \"DRY LAND\" in text:\n",
    "        imagen = Image.new(\"RGB\", (128, 128), (255,0,0))\n",
    "        imagen.save(f\"./chunks_process/{path}\")\n",
    "    elif \"FOREST\" in text:\n",
    "        imagen = Image.new(\"RGB\", (128, 128), (0,255,0))\n",
    "        imagen.save(f\"./chunks_process/{path}\")\n",
    "\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1m 23s para 25 imagenes de 128x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 128\n",
      "0 256\n",
      "0 384\n",
      "0 512\n",
      "128 0\n",
      "128 128\n",
      "128 256\n",
      "128 384\n",
      "128 512\n",
      "256 0\n",
      "256 128\n",
      "256 256\n",
      "256 384\n",
      "256 512\n",
      "384 0\n",
      "384 128\n",
      "384 256\n",
      "384 384\n",
      "384 512\n",
      "512 0\n",
      "512 128\n",
      "512 256\n",
      "512 384\n",
      "512 512\n"
     ]
    }
   ],
   "source": [
    "archivos = os.listdir(\"./chunks_process\")\n",
    "archivos = sorted(archivos, key=lambda x: (int(x.replace(\".jpg\", \"\").split(\"-\")[0]), int(x.replace(\".jpg\", \"\").split(\"-\")[1])))\n",
    "ancho, alto = 640, 640\n",
    "tamaño_trozo = 128\n",
    "new_image = Image.new('RGB', (ancho, alto))\n",
    "\n",
    "for i, path in enumerate(archivos):\n",
    "    image = Image.open(f\"./chunks_process/{path}\")\n",
    "    pos_x, pos_y = (int(path.replace(\".jpg\", \"\").split(\"-\")[0]), int(path.replace(\".jpg\", \"\").split(\"-\")[1]))\n",
    "    print(pos_x * tamaño_trozo , pos_y* tamaño_trozo)\n",
    "    new_image.paste(image, (tamaño_trozo * pos_x, tamaño_trozo  * pos_y))\n",
    "new_image.save(\"result.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archivos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
